\documentclass[12pt]{article}
\usepackage[pdftex]{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\pagestyle{empty}
\author{Chris Camano: ccamano@sfsu.edu}
\title{MATH 425  Lecture 18 }
\date{4/14/2022}

\topmargin -0.6in
\headsep 0.40in
\oddsidemargin 0.0in
\textheight 9.0in
\textwidth 6.5in

\newcommand{\econst}{\mathrm{e}}
\newcommand{\diff}{\mathrm{d}}
\newcommand{\dwrt}[1]{\frac{\diff}{\diff #1}}
%%%%%%Macros for 425%%%%%%%%%%%%%%%%%%%
\newcommand{\q}{\quad}
\newcommand{\tab}{\\\\}
\renewcommand{\labelenumi}{\alph{enumi})}
\newcommand{\sect}[1]{\section*{#1}}

%%%%%%Vector Spaces%%%%%%%%%%%%%%%%%%%
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\F}{\mathbb{F}}
\newcommand{\rtwo}{\mathbb{R}^2}
\newcommand{\mxn}{{mxn}}

%%%%%%Sets and common phrases%%%%%%%%%
\newcommand{\Axb}{\textbf{Ax=b} }
\newcommand{\Axz}{\textbf{Ax=0} }
\newcommand{\dim}{\text{dim}}
\newcommand{\lc}{linear combination }
\newcommand{\let}{\text{Let }}
\newcommand{\tf}{\therefore}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\everymath={\displaystyle}


\begin{document}
\maketitle

\sect{Problem 1}
\begin{proof}
  \begin{proof}
    Find an orthogonal basis for the column space of the matrix A:
    \[
      \begin{bmatrix}
        -1&6&6\\3&-8&3\\1&-2&6\\1&-4&-3
      \end{bmatrix}
    \]
    For this problem I will use gramn schmidt orthogonalization to obtain an orthonormal basis for the columns of A.
    \[
      \text{Let }u_1=\begin{bmatrix}
        -1\\3\\1\\1
    \end{bmatrix}
    \]
    \[
      \text{Let }u_2=\begin{bmatrix}
        6\\-8\\-2\\-4
    \end{bmatrix}-
    \frac{  \begin{bmatrix}
      6\\-8\\-2\\-4
  \end{bmatrix}\cdot \begin{bmatrix}
        -1\\3\\1\\1
    \end{bmatrix}}{\begin{bmatrix}
      -1\\3\\1\\1
  \end{bmatrix} \cdot \begin{bmatrix}
      -1\\3\\1\\1
  \end{bmatrix}}\begin{bmatrix}
      -1\\3\\1\\1
  \end{bmatrix}=\begin{bmatrix}
    3\\1\\1\\-1
  \end{bmatrix}
    \]

    \[
    \text{Let } u_3=\begin{bmatrix}
        6\\3\\6\\-3
    \end{bmatrix}-\frac{{\begin{bmatrix}
      6\\3\\6\\-3
    \end{bmatrix}\cdot  \begin{bmatrix}
        -1\\3\\1\\1
    \end{bmatrix}}}{\begin{bmatrix}
          -1\\3\\1\\1
      \end{bmatrix}\cdot \begin{bmatrix}
            -1\\3\\1\\1
        \end{bmatrix}}\begin{bmatrix}
              -1\\3\\1\\1
          \end{bmatrix}-\frac{v_3\cdot u_2}{u_2 \cdot u_2}u_2=  \renewcommand\arraystretch{2}\begin{bmatrix}
          -1\\\-1\\3\\-1
        \end{bmatrix}
    \]
    Thus the set :
    \[
      \Bigg\{\begin{bmatrix}
        -1\\3\\1\\1
    \end{bmatrix},\begin{bmatrix}
      3\\1\\1\\-1
    \end{bmatrix},\renewcommand\arraystretch{2}\begin{bmatrix}
      -1\\\-1\\3\\-1
  \end{bmatrix}\Bigg\}
    \]
    Forms an orthogonal basis for the given vectors. To validate this claim I have checked that all three vectors in the described set are orthogonal to one another computationally.
  \end{proof}
\sect{Problem 2}
\begin{proof}

  2. Find an orthonormal basis for the column space of the matrix $ A = \begin{bmatrix}~~3 & -3 &~~0\\-4 & ~14 & 10\\~~5 & -7 & -2\end{bmatrix}$ .
  \vskip 10pt
First note that A $\sim$ \begin{bmatrix}
  1&0&1\\0&1&1\\0&0&0
\end{bmatrix} Let $\{v_1,v_2,v_3\}$ denote the columns of A. The columns space of A is $\{v_1,v_2\}$ as these are the linearly independent columns of A. To obtain an orthonormal basis for A we will first compute an orthogonal basis then normalize. The orthogonal basis of the column space of A can be found using gram schmidt.

\begin{align*}
  &u_1=v_1
  &u_2=v_2-\frac{v_2\cdot u_1}{u_1 \cdot u_1}u_1=\begin{bmatrix}
    3\\6\\3
  \end{bmatrix}\\
\end{bmatrix}
\end{align*}
Normalizing both:
\begin{align*}
  &e_1=\frac{u_1}{||u_1||}=\frac{u_1}{5\sqrt{2}}\\
  &e_2=\frac{u_2}{||u_2||}=\frac{u_2}{3\sqrt{6}}\\
\end{align*}
Thus: $\{\frac{1}{5\sqrt{2}}u_1,\frac{1}{3\sqrt{6}}u_2\}$ form an orthonormal basis for the column space of A. also note that the dotproduct of $e_1$ and $e_2$ is zero.
\end{proof}
\sect{Problem 3}
\begin{proof}
  3.  Let ${\bf u}_1,\ldots, {\bf u}_p$ be an orthogonal basis for the subspace $W$ of ${\Bbb R}^n$,
  and let $T: {\Bbb R}^n \rightarrow {\Bbb R}^n$ be defined by $ T({\bf x}) = \text{proj}_W {\bf x}$. Show that $T$ is a linear transformation.
  \vskip 10pt
  \noindent

    Let $u_1,...u_p$ be an orthogonal basis for the subspace W of $\R^n$ and let T: $
    \R^n \mapsto \R^n$ ve defined by T(x)=proj$_Wx$ Show that T is a linear transformation.
  \[
    T(x)=\frac{x\cdot u_1}{||u_1||}u_1+...+\frac{x\cdot u_n}{||u_n||}u_n
  \]
  \[
    T(cx+y)=\frac{(cx_1+y_1)\cdot u_1}{||u_1||}u_1+....+\frac{(cx_p+y_p)\cdot u_p}{||u_p||}u_p
  \]
  \[
    T(cx+y)=\frac{(cx_1\cdot u_1+y_1\cdot u_1)}{||u_1||}u_1+....+\frac{(cx_p\cdot u_p+y_p\cdot u_p)}{||u_p||}u_p
  \]
  \[
    T(cx+y)=\frac{(cx_1\cdot u_1)}{||u_1||}u_1+\frac{y_1\cdot u_1}{||u_1||}u_1....+\frac{(cx_1\cdot u_p)}{||u_p||}u_p+\frac{y_p\cdot u_p}{||u_p||}u_p
  \]
  \[
    T(cx+y)=  T(cx+y)=\frac{(cx_1\cdot u_1)}{||u_1||}u_1....+\frac{(cx_1\cdot u_p)}{||u_p||}u_p+T(y)
  \]
  \[
    T(cx+y)=cT(x)+T(y)
  \]
\end{proof}
\sect{Problem 4}
\begin{proof}
  4. Let $A = \begin{bmatrix}~~1 & 2\\-1 & 4\\~~1 & 2\end{bmatrix}$ and ${\bf b} = \begin{bmatrix} ~~3\\ -1\\~~5\end{bmatrix}$.
  Find (a) the orthogonal projection of ${\bf b}$ onto $\text{Col}~A$ and (b) a least-squares solution of
  $A{\bf x} = {\bf b}$.
  \vskip 10pt

  Note that the columns of A already form an orthogonal basis ! The two columns are linearly independent and are orthogonal to one another. This means that to compute the orthogonal projection of b onto colA we can proceed normally:
  \[
    proj_b(ColA)=\frac{b\cdot a_1}{a_1\cdot a_1}a_1+\frac{b \cdot a_2}{a_2 \cdot a_2}a_2=3a_1+\frac{1}{2}a_2=\begin{bmatrix}
      4\\-1\\4
  \end{bmatrix}
  \]
  To find the least squares solution we must compute:
  \[
    A^TAx=A^Tb
  \]
  \begin{align*}
    &\begin{bmatrix}
      3&0\\0&24
  \end{bmatrix}x=\begin{bmatrix}
    9\\12
  \end{bmatrix}\\
  &x=\begin{bmatrix}
    3\\\frac{1}{2}
  \end{bmatrix}
    \end{align*}
      Meaning that the least squares solution is $3a_1+\frac{1}{2}a_2$ which is the same as shown above during th computation of the orthgonal projection of b onto the columns space.
  \end{proof}
\sect{Problem 5}
\begin{proof}
    5. Let $A = \begin{bmatrix}~~2 & 1\\-2 & 0\\~~2 & 3\end{bmatrix}$ and ${\bf b} = \begin{bmatrix}-5\\~~8\\~~1\end{bmatrix}$. Find the least-squares solution of $A~{\bf x} = {\bf b}$.
    \vskip 10pt
  \[
    A^TAx=A^Tb
  \]
  \begin{align*}
    &\begin{bmatrix}
      12&8\\8&10
    \end{bmatrix}x=A^tb\\
    &\begin{bmatrix}
      12&8\\8&10
    \end{bmatrix}x=\begin{bmatrix}
    -24\\-2
    \end{bmatrix}\\
    &x=\begin{bmatrix}
      -4\\3
  \end{bmatrix}
  \end{align*}
  Thus $-4a_1+3a_2 =\begin{bmatrix}
    -5\\8\\1
  \end{bmatrix}$ is the least squares solution. Also note that this means that b is in the columns space of A and could have been found simply by reducing the augmented matrix [A$|$b]. You got me!
\end{proof}
\sect{Problem 6}
\begin{proof}
    6. Let
    \[
    A = \begin{bmatrix}1 & 1 & 0\\1 & 1 & 0\\1 & 1 & 0\\ 1 & 0 & 1\\ 1 & 0 & 1 \\1 & 0 & 1 \end{bmatrix} \hskip 20pt \text{and } {\bf b} = \begin{bmatrix} 7\\ 2\\3\\6\\5\\4\end{bmatrix}.
    \]

     Describe all
    least-squares solutions of the equation $A{\bf x} = {\bf b}$.
    \vskip 10pt
    After solving the equation $A^TAx=A^Tb$ you obtain the following:
    \[
      \begin{bmatrix}
        1&0&1&5\\0&1&-1&-1\\0&0&0&0
      \end{bmatrix}
    \]
    The solution $\hat{x}$ takes the form $\begin{bmatrix}
      5\\-1\\0
  \end{bmatrix}+\begin{bmatrix}
    -1\\1\\1
  \end{bmatrix}x_3\text{ }$  since the variable $x_3$ is free.
\end{proof}
\sect{Problem 7}**** possibly wrong
\begin{proof}
  7. Let
  \[
  A = \begin{bmatrix}1 & -1 \\1 & ~~4\\1 & -1\\1 & ~~4\end{bmatrix} = \begin{bmatrix} 1/2 & -1/2\\ 1/2 & ~~1/2 \\1/2 & - 1/2 \\1/2 & ~~1/2\end{bmatrix}~\begin{bmatrix}2 & 3\\0 & 5\end{bmatrix},\hskip 20pt
  \]
  be the factorization $A = QR$ and let ${\bf b} = \begin{bmatrix} -1\\~~6\\~~5\\~~7\end{bmatrix}$.
  Use the $QR$ factorization to find the least-squares solution of $A{\bf x} = {\bf b}$.
  \begin{align*}
    &QRx=b\\
    &Q^TQRx=Q^Tb\\
    &Rx=Q^Tb\\
  \end{align*}
  \[
  \renewcommand{\arraystretch}{2}
    b=\begin{bmatrix}2 & 3\\0 & 5\end{bmatrix}x=\begin{bmatrix}
    \frac{1}{2}&  \frac{1}{2}&  \frac{1}{2}&  \frac{1}{2}\\
    -  \frac{1}{2}&  \frac{1}{2}&- \frac{1}{2}&  \frac{1}{2}
\end{bmatrix}\begin{bmatrix} -1\\~~6\\~~5\\~~7\end{bmatrix}
  \]
\[
\renewcommand{\arraystretch}{2}
  \begin{bmatrix}
    2&3&\frac{17}{2}\\0&5&\frac{9}{10}
  \end{bmatrix}\sim\begin{bmatrix}
    1&0&\frac{29}{10}\\0&1&\frac{9}{10}
\end{bmatrix}
\]
meaning that the least squares solution for b is $\hat{x}=\frac{29}{10}a_1+\frac{9}{2}a_2$ where $a_1,a_2$ are the columns of A
\end{proof}
\sect{Problem 8}
\begin{proof}
  8. A healthy child's systolic blood pressure $p$ (in millimeters of mercury) and weight $w$ (in pounds) are approximately related by the equation
  \[
  \beta_0 + \beta_1\ln w = p.
  \]
  Use the following experimental data to estimate the systolic blood pressure of a healthy child weighing 100 pounds.
  \begin{center}
  \begin{tabular}{l | c c c c c}
  $w$ & 44 & 61 & 81 & 113 & 131 \\
  \hline
  $\ln w$ & 3.78 & 4.11 & 4.41 & 4.73 & 4.88\\
  \hline
  $p$ & 91 & 98 & 103 & 110 & 112
  \end{tabular}
  \end{center}
  \vskip 10pt
  To solve this problem we will use least squares regression with a linear line of regression with the following:
  \[
    X=\begin{bmatrix}
      1&3.78\\
      1&4.11\\
      1&4.41\\
      1&4.73\\
      1&4.88\\
  \end{bmatrix}
  y=\begin{bmatrix}
    91\\98\\103\\110\\112
\end{bmatrix}
  \]
  \begin{align*}
    &X^TX\beta=X^Ty\\
    &\begin{bmatrix}
      5&21.91\\21.91&96.8159
  \end{bmatrix}\beta=\begin{bmatrix}
    514\\2267.85
\end{bmatrix}
  \end{align*}
  reduing we get: $\beta=\begin{bmatrix}
    18.5492\\19.2266
\end{bmatrix}$ implying that $\rho$=18.5492+19.2266ln(w).
To predict the blood pressure of a young boy weighing 100 pounds we can use this function evaluated at w=100.
\[
  \rho=18.5492+19.2266ln(100)=107.091
\]
So a young boy weighing 100 pounds has approximately a systolic blood pressure of 107 ml of mercury.
\end{proof}
\sect{Problem 9}
\begin{proof}

  9. To measure the takeoff performance of an airplane, the horizontal position of the plane was measured every second, from $t = 0$ to $t=12$. The positions (in feet) were: 0, ~8.8, ~29.9, ~62.0,~ 104.7,~ 159.1,~ 222.0, ~294.5, ~ 380.4,~ 471.1,~ 571.7,~, 686.8,~ 809.2 .
  \begin{itemize}
  \item[(a)] Find the least-squares cubic curve $y = \beta_0 + \beta_1 t + \beta_2 t^2 + \beta_3 t^3$ for these data.
  \item[(b)] Use the result of (a) to estimate the velocity of the plane when $t = 4.5$ seconds.
  \end{itemize}
  \vskip 10pt
  To solve this problem we will use least squares regression with a linear line of regression with the following:
  \[
    X=\begin{bmatrix}
    1&0&0&0\\
      1&1&1&1\\
      1&2&4&8\\
      1&3&9&27\\
      1&4&16&64\\
      1&5&25&125\\
      1&6&36&216\\
      1&7&49&343\\
      1&8&64&512\\
      1&9&81&729\\
      1&10&100&1000\\
      1&11&121&1331\\
      1&12&144&1728\\
  \end{bmatrix}
  y=\begin{bmatrix}
    0\\8.8\\29.9\\62.0\\104.7\\159.1\\222.0\\294.5\\380.4\\471.1\\571.1\\686.8\\809.2
\end{bmatrix}
  \]
  Solving for beta in the following equation $X^TX\beta=X^Ty\\$:Using python gives the following vector:
  \[
    \begin{bmatrix}
      -.86\\4.7\\5.56\\-.027
    \end{bmatrix}
  \]
Thus the equation of the cubic curve is:
\[
  y=-.8558+4.7025t+5.5554t^2-.0274t^3
\]

The equation evaluated at t=4.5 is yeilds a horizontal position of 130.42ft.

To find the velocity at 4.5 seconds we can compute the time derivative of position which gives.
\[
    v=4.7025+11.11086t-.0822t^2
\]
evaluated at 4.5 seconds the veloicty is
$$53.0368$$ feet per second
\end{proof}
\end{document}
